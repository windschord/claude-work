# éŸ³å£°æ©Ÿèƒ½ ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢è¨­è¨ˆæ›¸ (SDD)

## 1. æ¦‚è¦

### 1.1 ç›®çš„

ClaudeWorkã«éŸ³å£°å…¥åŠ›ï¼ˆSpeech-to-Textï¼‰ã¨éŸ³å£°èª­ã¿ä¸Šã’ï¼ˆText-to-Speechï¼‰æ©Ÿèƒ½ã‚’è¿½åŠ ã—ã€ãƒãƒ³ã‚ºãƒ•ãƒªãƒ¼ã§ã®Claude Codeæ“ä½œã‚’å¯èƒ½ã«ã™ã‚‹ã€‚

### 1.2 ã‚¹ã‚³ãƒ¼ãƒ—

- **éŸ³å£°å…¥åŠ›**: ãƒã‚¤ã‚¯ã‹ã‚‰ã®éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã—ã€Claude Codeã¸é€ä¿¡
- **éŸ³å£°èª­ã¿ä¸Šã’**: Claude Codeã®å‡ºåŠ›ãƒ†ã‚­ã‚¹ãƒˆã‚’éŸ³å£°ã§èª­ã¿ä¸Šã’

### 1.3 å‚è€ƒè³‡æ–™

- [Web Speech API - MDN](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API)
- [Whisper-Web (Transformers.js)](https://github.com/xenova/whisper-web)
- [Web Speech API SpeechSynthesis - MDN](https://developer.mozilla.org/en-US/docs/Web/API/SpeechSynthesis)

---

## 2. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æ¦‚è¦

### 2.1 ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆå›³

```mermaid
graph TD
    subgraph "ãƒ–ãƒ©ã‚¦ã‚¶ (ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ)"
        Mic[ğŸ¤ ãƒã‚¤ã‚¯]
        Speaker[ğŸ”Š ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼]

        subgraph "éŸ³å£°å…¥åŠ›ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"
            MediaRecorder[MediaRecorder API]
            SpeechRecognition[Web Speech API<br/>SpeechRecognition]
            WhisperJS[Whisper.js<br/>ã‚ªãƒ—ã‚·ãƒ§ãƒ³]
        end

        subgraph "éŸ³å£°å‡ºåŠ›ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"
            SpeechSynthesis[Web Speech API<br/>SpeechSynthesis]
            AudioPlayer[Audio Player]
        end

        subgraph "æ—¢å­˜ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ"
            InputForm[InputForm.tsx]
            MessageBubble[MessageBubble.tsx]
            WebSocketHook[useWebSocket.ts]
            Store[Zustand Store]
        end
    end

    subgraph "ã‚µãƒ¼ãƒãƒ¼ (ã‚ªãƒ—ã‚·ãƒ§ãƒ³æ‹¡å¼µ)"
        WhisperServer[Whisper Server<br/>ã‚ªãƒ—ã‚·ãƒ§ãƒ³]
        TTSServer[TTS Server<br/>ã‚ªãƒ—ã‚·ãƒ§ãƒ³]
    end

    Mic --> MediaRecorder
    MediaRecorder --> SpeechRecognition
    MediaRecorder -.-> WhisperJS
    MediaRecorder -.-> WhisperServer

    SpeechRecognition --> InputForm
    WhisperJS --> InputForm
    WhisperServer --> InputForm

    InputForm --> WebSocketHook
    WebSocketHook --> Store

    Store --> MessageBubble
    MessageBubble --> SpeechSynthesis
    MessageBubble -.-> TTSServer

    SpeechSynthesis --> Speaker
    TTSServer -.-> AudioPlayer
    AudioPlayer --> Speaker
```

### 2.2 æŠ€è¡“é¸å®š

#### éŸ³å£°å…¥åŠ›ï¼ˆSpeech-to-Textï¼‰

| ã‚ªãƒ—ã‚·ãƒ§ãƒ³ | åˆ©ç‚¹ | æ¬ ç‚¹ | æ¨å¥¨åº¦ |
|-----------|------|------|--------|
| **Web Speech API (SpeechRecognition)** | ãƒ–ãƒ©ã‚¦ã‚¶æ¨™æº–ã€å®Ÿè£…å®¹æ˜“ã€ä½ã‚³ã‚¹ãƒˆ | Chrome/Edgeé™å®šã€ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ä¾å­˜ | â­â­â­ **æ¨å¥¨ï¼ˆPhase 1ï¼‰** |
| Whisper.js (Transformers.js) | ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å¯¾å¿œã€é«˜ç²¾åº¦ | åˆå›ãƒ­ãƒ¼ãƒ‰å¤§ã€CPUè² è· | â­â­ Phase 2 |
| Whisper Server (OpenAI API) | æœ€é«˜ç²¾åº¦ | ã‚³ã‚¹ãƒˆç™ºç”Ÿã€ãƒ¬ã‚¤ãƒ†ãƒ³ã‚· | â­ ã‚ªãƒ—ã‚·ãƒ§ãƒ³ |

#### éŸ³å£°å‡ºåŠ›ï¼ˆText-to-Speechï¼‰

| ã‚ªãƒ—ã‚·ãƒ§ãƒ³ | åˆ©ç‚¹ | æ¬ ç‚¹ | æ¨å¥¨åº¦ |
|-----------|------|------|--------|
| **Web Speech API (SpeechSynthesis)** | ãƒ–ãƒ©ã‚¦ã‚¶æ¨™æº–ã€ç„¡æ–™ã€ã‚ªãƒ•ãƒ©ã‚¤ãƒ³å¯¾å¿œ | éŸ³å£°å“è³ªã¯ç’°å¢ƒä¾å­˜ | â­â­â­ **æ¨å¥¨** |
| OpenAI TTS API | é«˜å“è³ªéŸ³å£° | ã‚³ã‚¹ãƒˆç™ºç”Ÿ | â­ ã‚ªãƒ—ã‚·ãƒ§ãƒ³ |

---

## 3. è©³ç´°è¨­è¨ˆ

### 3.1 éŸ³å£°å…¥åŠ›æ©Ÿèƒ½

#### 3.1.1 ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ§‹æˆ

```mermaid
graph LR
    subgraph "æ–°è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ"
        VoiceInputButton[VoiceInputButton.tsx]
        VoiceIndicator[VoiceIndicator.tsx]
    end

    subgraph "æ–°è¦Hooks"
        useSpeechRecognition[useSpeechRecognition.ts]
        useMediaRecorder[useMediaRecorder.ts]
    end

    subgraph "æ—¢å­˜ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆæ‹¡å¼µï¼‰"
        InputForm[InputForm.tsx]
        Header[Header.tsx]
    end

    subgraph "çŠ¶æ…‹ç®¡ç†ï¼ˆæ‹¡å¼µï¼‰"
        VoiceStore[voiceStore.ts]
    end

    VoiceInputButton --> useSpeechRecognition
    VoiceInputButton --> InputForm
    VoiceIndicator --> Header
    useSpeechRecognition --> VoiceStore
    useMediaRecorder --> useSpeechRecognition
```

#### 3.1.2 ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹å®šç¾©

```typescript
// src/types/voice.ts

/** éŸ³å£°å…¥åŠ›ã®çŠ¶æ…‹ */
export type VoiceInputStatus =
  | 'idle'           // å¾…æ©Ÿä¸­
  | 'listening'      // éŸ³å£°èªè­˜ä¸­
  | 'processing'     // å‡¦ç†ä¸­ï¼ˆWhisperä½¿ç”¨æ™‚ï¼‰
  | 'error';         // ã‚¨ãƒ©ãƒ¼

/** éŸ³å£°èªè­˜çµæœ */
export interface SpeechRecognitionResult {
  transcript: string;      // èªè­˜ãƒ†ã‚­ã‚¹ãƒˆ
  confidence: number;      // ä¿¡é ¼åº¦ (0-1)
  isFinal: boolean;       // ç¢ºå®šçµæœã‹ã©ã†ã‹
}

/** éŸ³å£°å…¥åŠ›è¨­å®š */
export interface VoiceInputSettings {
  enabled: boolean;                    // éŸ³å£°å…¥åŠ›æœ‰åŠ¹
  language: string;                    // èªè­˜è¨€èª (e.g., 'ja-JP', 'en-US')
  continuous: boolean;                 // é€£ç¶šèªè­˜ãƒ¢ãƒ¼ãƒ‰
  interimResults: boolean;             // ä¸­é–“çµæœè¡¨ç¤º
  autoSend: boolean;                   // èªè­˜å®Œäº†æ™‚ã«è‡ªå‹•é€ä¿¡
  silenceTimeout: number;              // ç„¡éŸ³ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ (ms)
}

/** éŸ³å£°å‡ºåŠ›è¨­å®š */
export interface VoiceOutputSettings {
  enabled: boolean;                    // éŸ³å£°èª­ã¿ä¸Šã’æœ‰åŠ¹
  voice: string | null;                // ä½¿ç”¨ã™ã‚‹éŸ³å£° (null = ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ)
  rate: number;                        // èª­ã¿ä¸Šã’é€Ÿåº¦ (0.1 - 10)
  pitch: number;                       // ãƒ”ãƒƒãƒ (0 - 2)
  volume: number;                      // éŸ³é‡ (0 - 1)
  autoRead: boolean;                   // ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå¿œç­”ã‚’è‡ªå‹•èª­ã¿ä¸Šã’
  readCodeBlocks: boolean;             // ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚‚èª­ã¿ä¸Šã’
}
```

#### 3.1.3 useSpeechRecognition Hook

```typescript
// src/hooks/useSpeechRecognition.ts

interface UseSpeechRecognitionReturn {
  // çŠ¶æ…‹
  isListening: boolean;
  isSupported: boolean;
  error: string | null;
  transcript: string;
  interimTranscript: string;

  // ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
  startListening: () => void;
  stopListening: () => void;
  resetTranscript: () => void;

  // è¨­å®š
  setLanguage: (lang: string) => void;
}

export function useSpeechRecognition(
  options?: Partial<VoiceInputSettings>
): UseSpeechRecognitionReturn {
  // Web Speech API SpeechRecognition ã‚’ä½¿ç”¨
  // ãƒ–ãƒ©ã‚¦ã‚¶äº’æ›æ€§: Chrome, Edge, Safari (webkit prefix)
  // Firefox: æœªã‚µãƒãƒ¼ãƒˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿…è¦ï¼‰
}
```

#### 3.1.4 VoiceInputButton ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

```typescript
// src/components/voice/VoiceInputButton.tsx

interface VoiceInputButtonProps {
  onTranscript: (text: string) => void;  // èªè­˜çµæœã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯
  disabled?: boolean;                     // ç„¡åŠ¹åŒ–
  className?: string;                     // ã‚¹ã‚¿ã‚¤ãƒ«
}

/**
 * ãƒã‚¤ã‚¯ãƒœã‚¿ãƒ³ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
 *
 * çŠ¶æ…‹è¡¨ç¤º:
 * - idle: ã‚°ãƒ¬ãƒ¼ã®ãƒã‚¤ã‚¯ã‚¢ã‚¤ã‚³ãƒ³
 * - listening: èµ¤ã„ç‚¹æ»…ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³
 * - processing: ã‚¹ãƒ”ãƒŠãƒ¼
 * - error: èµ¤ã„ãƒã‚¤ã‚¯ã‚¢ã‚¤ã‚³ãƒ³ + ãƒ„ãƒ¼ãƒ«ãƒãƒƒãƒ—
 */
export function VoiceInputButton({ onTranscript, disabled }: VoiceInputButtonProps) {
  const { isListening, startListening, stopListening, transcript } = useSpeechRecognition();

  // ãƒˆã‚°ãƒ«å‹•ä½œ: ã‚¯ãƒªãƒƒã‚¯ã§é–‹å§‹/åœæ­¢
  // èªè­˜å®Œäº†æ™‚ã« onTranscript ã‚’å‘¼ã³å‡ºã—
}
```

### 3.2 éŸ³å£°èª­ã¿ä¸Šã’æ©Ÿèƒ½

#### 3.2.1 ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ§‹æˆ

```mermaid
graph LR
    subgraph "æ–°è¦ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ"
        VoicePlayButton[VoicePlayButton.tsx]
        VoiceSettingsPanel[VoiceSettingsPanel.tsx]
    end

    subgraph "æ–°è¦Hooks"
        useSpeechSynthesis[useSpeechSynthesis.ts]
    end

    subgraph "æ—¢å­˜ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆï¼ˆæ‹¡å¼µï¼‰"
        MessageBubble[MessageBubble.tsx]
        NotificationSettings[NotificationSettings.tsx]
    end

    VoicePlayButton --> useSpeechSynthesis
    VoicePlayButton --> MessageBubble
    VoiceSettingsPanel --> NotificationSettings
```

#### 3.2.2 useSpeechSynthesis Hook

```typescript
// src/hooks/useSpeechSynthesis.ts

interface UseSpeechSynthesisReturn {
  // çŠ¶æ…‹
  isSpeaking: boolean;
  isPaused: boolean;
  isSupported: boolean;
  voices: SpeechSynthesisVoice[];

  // ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
  speak: (text: string, options?: SpeakOptions) => void;
  pause: () => void;
  resume: () => void;
  cancel: () => void;

  // è¨­å®š
  setVoice: (voice: SpeechSynthesisVoice) => void;
  setRate: (rate: number) => void;
  setPitch: (pitch: number) => void;
  setVolume: (volume: number) => void;
}

interface SpeakOptions {
  voice?: SpeechSynthesisVoice;
  rate?: number;
  pitch?: number;
  volume?: number;
  onEnd?: () => void;
  onError?: (error: Error) => void;
}
```

#### 3.2.3 VoicePlayButton ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ

```typescript
// src/components/voice/VoicePlayButton.tsx

interface VoicePlayButtonProps {
  text: string;                    // èª­ã¿ä¸Šã’ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
  disabled?: boolean;
  className?: string;
}

/**
 * èª­ã¿ä¸Šã’ãƒœã‚¿ãƒ³ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
 *
 * çŠ¶æ…‹è¡¨ç¤º:
 * - idle: ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ã‚¢ã‚¤ã‚³ãƒ³
 * - speaking: éŸ³æ³¢ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ + åœæ­¢ãƒœã‚¿ãƒ³
 * - paused: ä¸€æ™‚åœæ­¢ã‚¢ã‚¤ã‚³ãƒ³
 */
export function VoicePlayButton({ text, disabled }: VoicePlayButtonProps) {
  const { speak, cancel, isSpeaking } = useSpeechSynthesis();

  // ã‚¯ãƒªãƒƒã‚¯ã§å†ç”Ÿ/åœæ­¢ãƒˆã‚°ãƒ«
  // Markdownã‹ã‚‰ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡ºã—ã¦èª­ã¿ä¸Šã’
}
```

### 3.3 çŠ¶æ…‹ç®¡ç†

#### 3.3.1 Voice Store

```typescript
// src/store/voice.ts

import { create } from 'zustand';
import { persist } from 'zustand/middleware';

interface VoiceState {
  // éŸ³å£°å…¥åŠ›è¨­å®š
  inputSettings: VoiceInputSettings;
  inputStatus: VoiceInputStatus;

  // éŸ³å£°å‡ºåŠ›è¨­å®š
  outputSettings: VoiceOutputSettings;
  currentlySpeakingMessageId: string | null;

  // ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
  updateInputSettings: (settings: Partial<VoiceInputSettings>) => void;
  updateOutputSettings: (settings: Partial<VoiceOutputSettings>) => void;
  setInputStatus: (status: VoiceInputStatus) => void;
  setSpeakingMessage: (messageId: string | null) => void;
}

export const useVoiceStore = create<VoiceState>()(
  persist(
    (set) => ({
      inputSettings: {
        enabled: false,
        language: 'ja-JP',
        continuous: true,
        interimResults: true,
        autoSend: false,
        silenceTimeout: 2000,
      },
      inputStatus: 'idle',
      outputSettings: {
        enabled: false,
        voice: null,
        rate: 1.0,
        pitch: 1.0,
        volume: 1.0,
        autoRead: false,
        readCodeBlocks: false,
      },
      currentlySpeakingMessageId: null,

      updateInputSettings: (settings) =>
        set((state) => ({
          inputSettings: { ...state.inputSettings, ...settings },
        })),
      updateOutputSettings: (settings) =>
        set((state) => ({
          outputSettings: { ...state.outputSettings, ...settings },
        })),
      setInputStatus: (status) => set({ inputStatus: status }),
      setSpeakingMessage: (messageId) => set({ currentlySpeakingMessageId: messageId }),
    }),
    {
      name: 'voice-settings',
      partialize: (state) => ({
        inputSettings: state.inputSettings,
        outputSettings: state.outputSettings,
      }),
    }
  )
);
```

### 3.4 UIçµ±åˆ

#### 3.4.1 InputForm æ‹¡å¼µ

```typescript
// src/components/session/InputForm.tsx ã®æ‹¡å¼µ

export function InputForm({ onSubmit, disabled }: InputFormProps) {
  const [message, setMessage] = useState('');
  const { inputSettings } = useVoiceStore();

  const handleVoiceTranscript = (transcript: string) => {
    if (inputSettings.autoSend) {
      onSubmit(transcript);
    } else {
      setMessage((prev) => prev + ' ' + transcript);
    }
  };

  return (
    <form onSubmit={handleFormSubmit} className="flex items-end gap-2">
      <textarea
        value={message}
        onChange={(e) => setMessage(e.target.value)}
        // ... æ—¢å­˜ã®ãƒ—ãƒ­ãƒ‘ãƒ†ã‚£
      />

      {/* æ–°è¦: éŸ³å£°å…¥åŠ›ãƒœã‚¿ãƒ³ */}
      {inputSettings.enabled && (
        <VoiceInputButton
          onTranscript={handleVoiceTranscript}
          disabled={disabled}
        />
      )}

      <button type="submit" disabled={disabled || !message.trim()}>
        é€ä¿¡
      </button>
    </form>
  );
}
```

#### 3.4.2 MessageBubble æ‹¡å¼µ

```typescript
// src/components/session/MessageBubble.tsx ã®æ‹¡å¼µ

export function MessageBubble({ message }: MessageBubbleProps) {
  const { outputSettings } = useVoiceStore();

  // Markdownã‹ã‚‰ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’æŠ½å‡º
  const plainText = extractPlainText(message.content, {
    includeCodeBlocks: outputSettings.readCodeBlocks,
  });

  return (
    <div className={`message-bubble ${message.role}`}>
      <MessageDisplay content={message.content} />

      {/* æ–°è¦: èª­ã¿ä¸Šã’ãƒœã‚¿ãƒ³ï¼ˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ã¿ï¼‰ */}
      {message.role === 'assistant' && outputSettings.enabled && (
        <VoicePlayButton text={plainText} />
      )}

      <span className="timestamp">
        {formatTimestamp(message.createdAt)}
      </span>
    </div>
  );
}
```

#### 3.4.3 è¨­å®šãƒ‘ãƒãƒ«

```typescript
// src/components/voice/VoiceSettingsPanel.tsx

export function VoiceSettingsPanel() {
  const { inputSettings, outputSettings, updateInputSettings, updateOutputSettings } = useVoiceStore();
  const { voices } = useSpeechSynthesis();

  return (
    <div className="voice-settings-panel">
      <h3>éŸ³å£°è¨­å®š</h3>

      {/* éŸ³å£°å…¥åŠ›è¨­å®š */}
      <section>
        <h4>éŸ³å£°å…¥åŠ›</h4>
        <Toggle
          label="éŸ³å£°å…¥åŠ›ã‚’æœ‰åŠ¹åŒ–"
          checked={inputSettings.enabled}
          onChange={(enabled) => updateInputSettings({ enabled })}
        />
        <Select
          label="èªè­˜è¨€èª"
          value={inputSettings.language}
          options={[
            { value: 'ja-JP', label: 'æ—¥æœ¬èª' },
            { value: 'en-US', label: 'English (US)' },
          ]}
          onChange={(language) => updateInputSettings({ language })}
        />
        <Toggle
          label="èªè­˜å®Œäº†æ™‚ã«è‡ªå‹•é€ä¿¡"
          checked={inputSettings.autoSend}
          onChange={(autoSend) => updateInputSettings({ autoSend })}
        />
      </section>

      {/* éŸ³å£°å‡ºåŠ›è¨­å®š */}
      <section>
        <h4>éŸ³å£°èª­ã¿ä¸Šã’</h4>
        <Toggle
          label="èª­ã¿ä¸Šã’ã‚’æœ‰åŠ¹åŒ–"
          checked={outputSettings.enabled}
          onChange={(enabled) => updateOutputSettings({ enabled })}
        />
        <Select
          label="éŸ³å£°"
          value={outputSettings.voice ?? ''}
          options={voices.map((v) => ({ value: v.name, label: v.name }))}
          onChange={(voice) => updateOutputSettings({ voice })}
        />
        <Slider
          label="èª­ã¿ä¸Šã’é€Ÿåº¦"
          min={0.5}
          max={2.0}
          step={0.1}
          value={outputSettings.rate}
          onChange={(rate) => updateOutputSettings({ rate })}
        />
        <Toggle
          label="æ–°ã—ã„å¿œç­”ã‚’è‡ªå‹•èª­ã¿ä¸Šã’"
          checked={outputSettings.autoRead}
          onChange={(autoRead) => updateOutputSettings({ autoRead })}
        />
      </section>
    </div>
  );
}
```

---

## 4. ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ

### 4.1 æ–°è¦ä½œæˆãƒ•ã‚¡ã‚¤ãƒ«

```
src/
â”œâ”€â”€ types/
â”‚   â””â”€â”€ voice.ts                      # éŸ³å£°æ©Ÿèƒ½ã®å‹å®šç¾©
â”œâ”€â”€ hooks/
â”‚   â”œâ”€â”€ useSpeechRecognition.ts       # éŸ³å£°èªè­˜Hook
â”‚   â””â”€â”€ useSpeechSynthesis.ts         # éŸ³å£°åˆæˆHook
â”œâ”€â”€ components/
â”‚   â””â”€â”€ voice/
â”‚       â”œâ”€â”€ VoiceInputButton.tsx      # éŸ³å£°å…¥åŠ›ãƒœã‚¿ãƒ³
â”‚       â”œâ”€â”€ VoicePlayButton.tsx       # èª­ã¿ä¸Šã’ãƒœã‚¿ãƒ³
â”‚       â”œâ”€â”€ VoiceIndicator.tsx        # éŸ³å£°çŠ¶æ…‹ã‚¤ãƒ³ã‚¸ã‚±ãƒ¼ã‚¿ãƒ¼
â”‚       â””â”€â”€ VoiceSettingsPanel.tsx    # éŸ³å£°è¨­å®šãƒ‘ãƒãƒ«
â”œâ”€â”€ store/
â”‚   â””â”€â”€ voice.ts                      # éŸ³å£°çŠ¶æ…‹ç®¡ç†
â””â”€â”€ lib/
    â””â”€â”€ voice/
        â”œâ”€â”€ speech-recognition.ts     # SpeechRecognition ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
        â”œâ”€â”€ speech-synthesis.ts       # SpeechSynthesis ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£
        â””â”€â”€ text-processor.ts         # Markdownâ†’ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›
```

### 4.2 æ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´

| ãƒ•ã‚¡ã‚¤ãƒ« | å¤‰æ›´å†…å®¹ |
|----------|----------|
| `src/components/session/InputForm.tsx` | VoiceInputButton çµ±åˆ |
| `src/components/session/MessageBubble.tsx` | VoicePlayButton çµ±åˆ |
| `src/components/layout/Header.tsx` | VoiceIndicator è¿½åŠ  |
| `src/components/common/NotificationSettings.tsx` | VoiceSettingsPanel ã¸ã®ãƒªãƒ³ã‚¯è¿½åŠ  |
| `src/app/sessions/[id]/page.tsx` | è‡ªå‹•èª­ã¿ä¸Šã’ãƒ­ã‚¸ãƒƒã‚¯è¿½åŠ  |

---

## 5. ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼

### 5.1 éŸ³å£°å…¥åŠ›ãƒ•ãƒ­ãƒ¼

```mermaid
sequenceDiagram
    participant User as ãƒ¦ãƒ¼ã‚¶ãƒ¼
    participant Mic as ãƒã‚¤ã‚¯
    participant VIB as VoiceInputButton
    participant SR as SpeechRecognition
    participant IF as InputForm
    participant WS as WebSocket
    participant CC as Claude Code

    User->>VIB: ã‚¯ãƒªãƒƒã‚¯ï¼ˆéŒ²éŸ³é–‹å§‹ï¼‰
    VIB->>SR: startListening()
    SR->>Mic: éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£é–‹å§‹

    loop éŸ³å£°èªè­˜ä¸­
        Mic->>SR: éŸ³å£°ãƒ‡ãƒ¼ã‚¿
        SR->>VIB: onResult(interimTranscript)
        VIB->>IF: ä¸­é–“çµæœè¡¨ç¤ºï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    end

    User->>VIB: ã‚¯ãƒªãƒƒã‚¯ï¼ˆéŒ²éŸ³åœæ­¢ï¼‰ã¾ãŸã¯ç„¡éŸ³ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
    VIB->>SR: stopListening()
    SR->>VIB: onResult(finalTranscript)
    VIB->>IF: onTranscript(finalTranscript)

    alt autoSendæœ‰åŠ¹
        IF->>WS: send({ type: 'input', content: transcript })
        WS->>CC: ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
    else autoSendç„¡åŠ¹
        IF->>IF: ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã«è¿½åŠ 
        User->>IF: é€ä¿¡ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯
        IF->>WS: send({ type: 'input', content: message })
    end
```

### 5.2 éŸ³å£°èª­ã¿ä¸Šã’ãƒ•ãƒ­ãƒ¼

```mermaid
sequenceDiagram
    participant CC as Claude Code
    participant WS as WebSocket
    participant Store as Zustand Store
    participant MB as MessageBubble
    participant VPB as VoicePlayButton
    participant SS as SpeechSynthesis
    participant Speaker as ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼

    CC->>WS: å¿œç­”å‡ºåŠ›
    WS->>Store: handleWebSocketMessage()
    Store->>MB: æ–°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¿½åŠ 

    alt autoReadæœ‰åŠ¹
        MB->>VPB: è‡ªå‹•ãƒˆãƒªã‚¬ãƒ¼
        VPB->>SS: speak(plainText)
        SS->>Speaker: éŸ³å£°å†ç”Ÿ
    else æ‰‹å‹•å†ç”Ÿ
        Note over MB,VPB: ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå†ç”Ÿãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯
        VPB->>SS: speak(plainText)
        SS->>Speaker: éŸ³å£°å†ç”Ÿ
    end

    SS-->>VPB: onEnd()
    VPB->>Store: setSpeakingMessage(null)
```

---

## 6. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

### 6.1 éŸ³å£°å…¥åŠ›ã‚¨ãƒ©ãƒ¼

| ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥ | åŸå›  | å¯¾å‡¦ |
|-----------|------|------|
| `not-allowed` | ãƒã‚¤ã‚¯æ¨©é™æ‹’å¦ | æ¨©é™ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ€ã‚¤ã‚¢ãƒ­ã‚°è¡¨ç¤º |
| `no-speech` | éŸ³å£°æœªæ¤œå‡º | ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¾Œã«è‡ªå‹•åœæ­¢ |
| `network` | ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼ | ã‚ªãƒ•ãƒ©ã‚¤ãƒ³ãƒ¢ãƒ¼ãƒ‰æ¡ˆå†… |
| `aborted` | ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹ä¸­æ–­ | æ­£å¸¸çµ‚äº†ã¨ã—ã¦å‡¦ç† |
| `audio-capture` | ãƒã‚¤ã‚¯ã‚¨ãƒ©ãƒ¼ | ãƒ‡ãƒã‚¤ã‚¹ç¢ºèªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ |

### 6.2 éŸ³å£°èª­ã¿ä¸Šã’ã‚¨ãƒ©ãƒ¼

| ã‚¨ãƒ©ãƒ¼ç¨®åˆ¥ | åŸå›  | å¯¾å‡¦ |
|-----------|------|------|
| `canceled` | åˆ¥ã®èª­ã¿ä¸Šã’é–‹å§‹ | ç„¡è¦– |
| `interrupted` | ã‚·ã‚¹ãƒ†ãƒ å‰²ã‚Šè¾¼ã¿ | è‡ªå‹•å†é–‹ã‚ªãƒ—ã‚·ãƒ§ãƒ³ |
| `synthesis-failed` | åˆæˆã‚¨ãƒ©ãƒ¼ | ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸è¡¨ç¤º |

---

## 7. ãƒ–ãƒ©ã‚¦ã‚¶äº’æ›æ€§

### 7.1 éŸ³å£°å…¥åŠ› (SpeechRecognition)

| ãƒ–ãƒ©ã‚¦ã‚¶ | ã‚µãƒãƒ¼ãƒˆ | å‚™è€ƒ |
|----------|----------|------|
| Chrome | âœ… å®Œå…¨ã‚µãƒãƒ¼ãƒˆ | webkitSpeechRecognition |
| Edge | âœ… å®Œå…¨ã‚µãƒãƒ¼ãƒˆ | webkitSpeechRecognition |
| Safari | âš ï¸ éƒ¨åˆ†ã‚µãƒãƒ¼ãƒˆ | iOS/macOS ã®ã¿ |
| Firefox | âŒ æœªã‚µãƒãƒ¼ãƒˆ | ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯å¿…è¦ |

### 7.2 éŸ³å£°èª­ã¿ä¸Šã’ (SpeechSynthesis)

| ãƒ–ãƒ©ã‚¦ã‚¶ | ã‚µãƒãƒ¼ãƒˆ | å‚™è€ƒ |
|----------|----------|------|
| Chrome | âœ… å®Œå…¨ã‚µãƒãƒ¼ãƒˆ | - |
| Edge | âœ… å®Œå…¨ã‚µãƒãƒ¼ãƒˆ | - |
| Safari | âœ… å®Œå…¨ã‚µãƒãƒ¼ãƒˆ | - |
| Firefox | âœ… å®Œå…¨ã‚µãƒãƒ¼ãƒˆ | - |

### 7.3 éå¯¾å¿œãƒ–ãƒ©ã‚¦ã‚¶ã¸ã®å¯¾å¿œ

```typescript
// src/lib/voice/browser-support.ts

export function checkVoiceSupport() {
  return {
    speechRecognition: 'webkitSpeechRecognition' in window || 'SpeechRecognition' in window,
    speechSynthesis: 'speechSynthesis' in window,
  };
}

// éå¯¾å¿œã®å ´åˆã€éŸ³å£°ãƒœã‚¿ãƒ³ã‚’éè¡¨ç¤ºã¾ãŸã¯ã‚°ãƒ¬ãƒ¼ã‚¢ã‚¦ãƒˆ
// ãƒ„ãƒ¼ãƒ«ãƒãƒƒãƒ—ã§ã€ŒãŠä½¿ã„ã®ãƒ–ãƒ©ã‚¦ã‚¶ã¯éŸ³å£°æ©Ÿèƒ½ã«å¯¾å¿œã—ã¦ã„ã¾ã›ã‚“ã€ã‚’è¡¨ç¤º
```

---

## 8. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è€ƒæ…®äº‹é …

### 8.1 ãƒã‚¤ã‚¯æ¨©é™

- HTTPSç’°å¢ƒã§ã®ã¿ãƒã‚¤ã‚¯ä½¿ç”¨å¯èƒ½
- ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã‚‹æ˜ç¤ºçš„ãªæ¨©é™è¨±å¯ãŒå¿…è¦
- æ¨©é™çŠ¶æ…‹ã‚’æ°¸ç¶šåŒ–ã—ã€æ‹’å¦æ™‚ã¯å†ãƒªã‚¯ã‚¨ã‚¹ãƒˆã—ãªã„

### 8.2 ãƒ—ãƒ©ã‚¤ãƒã‚·ãƒ¼

- éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã¯ãƒ–ãƒ©ã‚¦ã‚¶å†…ã§å‡¦ç†ï¼ˆWeb Speech APIä½¿ç”¨æ™‚ï¼‰
- ã‚µãƒ¼ãƒãƒ¼ã¸ã®éŸ³å£°é€ä¿¡ã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼ˆWhisper Serverä½¿ç”¨æ™‚ã®ã¿ï¼‰
- è¨­å®šã§ã‚µãƒ¼ãƒãƒ¼é€ä¿¡ã®æœ‰ç„¡ã‚’æ˜ç¤º

### 8.3 ãƒ‡ãƒ¼ã‚¿ä¿å­˜

- éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã¯ä¸€æ™‚çš„ãªã‚‚ã®ã§æ°¸ç¶šåŒ–ã—ãªã„
- èªè­˜çµæœãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’é€šå¸¸ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦ä¿å­˜

---

## 9. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹è€ƒæ…®äº‹é …

### 9.1 éŸ³å£°èªè­˜

- é€£ç¶šèªè­˜ãƒ¢ãƒ¼ãƒ‰ã§ã®ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ç›£è¦–
- é•·æ™‚é–“ä½¿ç”¨æ™‚ã®è‡ªå‹•ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆè¨­å®šå¯èƒ½ï¼‰
- èªè­˜ä¸­ã¯ä»–ã®ãƒªã‚½ãƒ¼ã‚¹é›†ç´„çš„å‡¦ç†ã‚’æŠ‘åˆ¶

### 9.2 éŸ³å£°èª­ã¿ä¸Šã’

- é•·æ–‡ãƒ†ã‚­ã‚¹ãƒˆã®åˆ†å‰²èª­ã¿ä¸Šã’ï¼ˆæ–‡å˜ä½ï¼‰
- ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®ã‚¹ã‚­ãƒƒãƒ—ã‚ªãƒ—ã‚·ãƒ§ãƒ³
- èª­ã¿ä¸Šã’ã‚­ãƒ¥ãƒ¼ã®ç®¡ç†

---

## 10. å®Ÿè£…ãƒ•ã‚§ãƒ¼ã‚º

### Phase 1: åŸºæœ¬æ©Ÿèƒ½ï¼ˆæ¨å¥¨é–‹å§‹ç‚¹ï¼‰

1. å‹å®šç¾© (`src/types/voice.ts`)
2. éŸ³å£°èªè­˜Hook (`useSpeechRecognition.ts`)
3. éŸ³å£°åˆæˆHook (`useSpeechSynthesis.ts`)
4. Voice Store (`src/store/voice.ts`)
5. VoiceInputButton ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
6. VoicePlayButton ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
7. InputForm ã¸ã®çµ±åˆ
8. MessageBubble ã¸ã®çµ±åˆ

### Phase 2: è¨­å®šUI

1. VoiceSettingsPanel ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
2. NotificationSettings ã¸ã®çµ±åˆ
3. è¨€èªé¸æŠ
4. éŸ³å£°é¸æŠ
5. é€Ÿåº¦/ãƒ”ãƒƒãƒèª¿æ•´

### Phase 3: é«˜åº¦ãªæ©Ÿèƒ½ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

1. Whisper.js çµ±åˆï¼ˆã‚ªãƒ•ãƒ©ã‚¤ãƒ³èªè­˜ï¼‰
2. è‡ªå‹•èª­ã¿ä¸Šã’ãƒ¢ãƒ¼ãƒ‰
3. VoiceIndicatorï¼ˆãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤ºï¼‰
4. ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã‚·ãƒ§ãƒ¼ãƒˆã‚«ãƒƒãƒˆ

### Phase 4: ã‚µãƒ¼ãƒãƒ¼ã‚µã‚¤ãƒ‰æ‹¡å¼µï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰

1. Whisper Server çµ±åˆ
2. é«˜å“è³ªTTS API çµ±åˆ
3. éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜/å†ç”Ÿ

---

## 11. ãƒ†ã‚¹ãƒˆè¨ˆç”»

### 11.1 ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ

| ãƒ†ã‚¹ãƒˆå¯¾è±¡ | ãƒ†ã‚¹ãƒˆå†…å®¹ |
|-----------|-----------|
| useSpeechRecognition | ãƒ¢ãƒƒã‚¯ SpeechRecognition ã§ã®çŠ¶æ…‹é·ç§» |
| useSpeechSynthesis | ãƒ¢ãƒƒã‚¯ SpeechSynthesis ã§ã®å†ç”Ÿåˆ¶å¾¡ |
| Voice Store | è¨­å®šã®ä¿å­˜/èª­ã¿è¾¼ã¿ |
| text-processor | Markdownâ†’ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ› |

### 11.2 çµ±åˆãƒ†ã‚¹ãƒˆ

| ãƒ†ã‚¹ãƒˆå¯¾è±¡ | ãƒ†ã‚¹ãƒˆå†…å®¹ |
|-----------|-----------|
| VoiceInputButton + InputForm | éŸ³å£°å…¥åŠ›â†’ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ãƒ•ãƒ­ãƒ¼ |
| VoicePlayButton + MessageBubble | ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸èª­ã¿ä¸Šã’ãƒ•ãƒ­ãƒ¼ |
| VoiceSettingsPanel | è¨­å®šå¤‰æ›´ã®åæ˜  |

### 11.3 E2Eãƒ†ã‚¹ãƒˆ

| ãƒ†ã‚¹ãƒˆå¯¾è±¡ | ãƒ†ã‚¹ãƒˆå†…å®¹ |
|-----------|-----------|
| éŸ³å£°å…¥åŠ›ãƒ•ãƒ­ãƒ¼ | ãƒã‚¤ã‚¯æ¨©é™â†’éŒ²éŸ³â†’èªè­˜â†’é€ä¿¡ |
| éŸ³å£°èª­ã¿ä¸Šã’ãƒ•ãƒ­ãƒ¼ | å¿œç­”å—ä¿¡â†’èª­ã¿ä¸Šã’é–‹å§‹â†’å®Œäº† |
| è¨­å®šæ°¸ç¶šåŒ– | è¨­å®šå¤‰æ›´â†’ãƒªãƒ­ãƒ¼ãƒ‰â†’è¨­å®šç¶­æŒ |

---

## 12. ä¾å­˜é–¢ä¿‚

### 12.1 æ–°è¦ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ï¼ˆä¸è¦ï¼‰

Web Speech API ã¯ãƒ–ãƒ©ã‚¦ã‚¶æ¨™æº–APIã®ãŸã‚ã€è¿½åŠ ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¯ä¸è¦ã€‚

### 12.2 ã‚ªãƒ—ã‚·ãƒ§ãƒ³ä¾å­˜ï¼ˆPhase 3ä»¥é™ï¼‰

```json
{
  "@xenova/transformers": "^2.x.x"  // Whisper.js ä½¿ç”¨æ™‚
}
```

---

## 13. ä»˜éŒ²

### A. Web Speech API ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹

- [SpeechRecognition - MDN](https://developer.mozilla.org/en-US/docs/Web/API/SpeechRecognition)
- [SpeechSynthesis - MDN](https://developer.mozilla.org/en-US/docs/Web/API/SpeechSynthesis)

### B. é–¢é€£Issue/PR

- (å®Ÿè£…æ™‚ã«è¿½åŠ )

### C. å¤‰æ›´å±¥æ­´

| æ—¥ä»˜ | ãƒãƒ¼ã‚¸ãƒ§ãƒ³ | å¤‰æ›´å†…å®¹ |
|------|-----------|----------|
| 2025-12-25 | 1.0 | åˆç‰ˆä½œæˆ |
